# ğŸ“ Placement RAG Assistant

An intelligent RAG (Retrieval-Augmented Generation) system for querying placement and internship information using LLM-powered agents.

## ğŸ“‹ Overview

This system extracts, indexes, and retrieves placement information from various document formats (PDFs, images, text files) and provides an intelligent chatbot interface to answer queries about:

- ğŸ’° Stipend information
- ğŸ“ Job locations
- ğŸ“š Eligibility criteria (CGPA, branches)
- ğŸ¯ Selection/Interview processes
- ğŸ› ï¸ Required skills
- ğŸ“Š Company comparisons

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Query                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ§  LLM-Powered Agent                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Planner  â”‚â†’ â”‚ Executor  â”‚â†’ â”‚ Critic  â”‚â†’ â”‚ Synthesizer  â”‚   â”‚
â”‚  â”‚  (LLM)    â”‚  â”‚  (Tools)  â”‚  â”‚  (LLM)  â”‚  â”‚    (LLM)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ”§ Tools                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Facts Tool  â”‚  â”‚ Semantic Tool  â”‚  â”‚  Compare Tool     â”‚    â”‚
â”‚  â”‚ (Structured)â”‚  â”‚ (FAISS+Embed)  â”‚  â”‚  (Multi-company)  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ğŸ“š Data Indices                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Facts Index       â”‚      â”‚    Semantic Index           â”‚  â”‚
â”‚  â”‚ (JSON - Structured) â”‚      â”‚ (FAISS - Vector Embeddings) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
v_rag/
â”œâ”€â”€ extractor/              # Phase 1: Data Extraction
â”‚   â”œâ”€â”€ config.py           # Configuration settings
â”‚   â”œâ”€â”€ llm_client.py       # LLM client for extraction
â”‚   â”œâ”€â”€ ocr_extractor.py    # OCR for images
â”‚   â”œâ”€â”€ document_processor.py
â”‚   â””â”€â”€ run_extraction.py   # Main extraction script
â”‚
â”œâ”€â”€ rag/                    # Phase 2: RAG Indices
â”‚   â”œâ”€â”€ facts_index.py      # Structured facts index
â”‚   â”œâ”€â”€ semantic_index.py   # FAISS vector index
â”‚   â””â”€â”€ build_index.py      # Index builder
â”‚
â”œâ”€â”€ tools/                  # Phase 3: Query Tools
â”‚   â”œâ”€â”€ base_tool.py        # Base tool class
â”‚   â”œâ”€â”€ facts_tool.py       # Facts lookup tool
â”‚   â”œâ”€â”€ semantic_tool.py    # Semantic search tool
â”‚   â””â”€â”€ compare_tool.py     # Company comparison tool
â”‚
â”œâ”€â”€ agent/                  # Phase 4: LLM Agent
â”‚   â”œâ”€â”€ llm_client.py       # Agent LLM client
â”‚   â”œâ”€â”€ planner.py          # Query planning (LLM)
â”‚   â”œâ”€â”€ executor.py         # Tool execution
â”‚   â”œâ”€â”€ critic.py           # Result validation (LLM)
â”‚   â”œâ”€â”€ synthesizer.py      # Response generation (LLM)
â”‚   â””â”€â”€ orchestrator.py     # Main agent coordinator
â”‚
â”œâ”€â”€ web/                    # Phase 5: Web Interface
â”‚   â””â”€â”€ streamlit_app.py    # Streamlit chatbot UI
â”‚
â”œâ”€â”€ evaluation/             # Testing & Evaluation
â”‚   â”œâ”€â”€ test_queries.py     # Test cases
â”‚   â””â”€â”€ evaluate.py         # Evaluation script
â”‚
â”œâ”€â”€ output/                 # Extracted Data
â”‚   â”œâ”€â”€ facts.json          # Structured facts
â”‚   â””â”€â”€ semantic.json       # Semantic chunks
â”‚
â”œâ”€â”€ rag_index/              # Built Indices
â”‚   â”œâ”€â”€ facts_index.pkl     # Facts index
â”‚   â”œâ”€â”€ semantic.faiss      # FAISS index
â”‚   â””â”€â”€ semantic_metadata.json
â”‚
â”œâ”€â”€ run_agent.py            # CLI agent runner
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone/navigate to project
cd /home/ram/v_rag

# Install dependencies
pip install -r requirements.txt
pip install streamlit  # For web interface
```

### 2. Build Indices (if not already built)

```bash
# Extract data from documents
python -m extractor.run_extraction

# Build RAG indices
python -m rag.build_index
```

### 3. Run the Agent

#### Option A: Command Line Interface
```bash
python run_agent.py
```

#### Option B: Streamlit Web Interface
```bash
streamlit run web/streamlit_app.py --server.port 8501 --server.headless true
```

Access at: `http://localhost:8501` or via Jupyter proxy: `https://<server>/user/<username>/proxy/8501/`

## ğŸ’¬ Example Queries

| Query Type | Example |
|------------|---------|
| **Company Details** | "What is the selection process for Dell?" |
| **Stipend** | "What is the stipend offered by Intel?" |
| **Location Filter** | "Which companies are hiring in Bangalore?" |
| **Skills** | "What skills are required for data science roles?" |
| **Comparison** | "Compare Dell and Bosch internships" |
| **Aggregation** | "List companies with stipend more than 50000" |
| **Eligibility** | "What is the CGPA requirement for Amazon?" |

## ğŸ§  How It Works

### 1. **Planner (LLM)**
- Analyzes user query
- Extracts companies, attributes
- Selects appropriate tool(s)

### 2. **Executor**
- Runs selected tools
- Fetches facts (structured data)
- Fetches semantic data (descriptions)
- Enriches results with both

### 3. **Critic (LLM)**
- Validates completeness
- Checks relevance
- Decides if retry needed

### 4. **Synthesizer (LLM)**
- Combines facts + semantic data
- Generates natural response
- Formats with proper structure

## ğŸ”§ Configuration

Key settings in `extractor/config.py`:

```python
# LLM Model
LLM_MODEL = "Qwen/Qwen2.5-7B-Instruct"

# Embedding Model
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

# Data paths
DATA_PATH = "/path/to/placement/data"
OUTPUT_PATH = "/home/ram/v_rag/output"
```

## ğŸ“Š Data Format

### Facts (Structured)
```json
{
  "company_name": "Dell",
  "role_title": "Graduate Intern",
  "stipend_salary": {"amount": "35000", "currency": "INR", "period": "per month"},
  "location": ["Bangalore"],
  "eligibility": {"cgpa_pg": "8", "branches": ["CSE", "IT"]},
  "selection_process": [{"round": 1, "name": "Online Test"}]
}
```

### Semantic (Chunks)
```json
{
  "company": "Dell",
  "type": "interview_process",
  "content": "Round 1: Online Test - 90 min, 17 questions..."
}
```

## ğŸ› ï¸ Tools Available

| Tool | Purpose | Actions |
|------|---------|---------|
| **facts_lookup** | Structured queries | `get_company_details`, `filter_by_location`, `filter_by_stipend`, `filter_by_cgpa` |
| **semantic_search** | Descriptive info | `skills_required`, `interview_process`, `about_company` |
| **compare_companies** | Comparisons | `table`, `detailed`, `ranking` |
| **hybrid_search** | Combined | Facts + Semantic together |

## ğŸ“ˆ Evaluation

Run evaluation suite:
```bash
python -m evaluation.evaluate
```

## ğŸ¤ Contributing

1. Add new companies: Place documents in data folder, run extraction
2. Add new tools: Extend `tools/base_tool.py`
3. Improve prompts: Edit system prompts in agent components

## ğŸ“ License

MIT License

---

Built with â¤ï¸ using LLMs, FAISS, and Streamlit
