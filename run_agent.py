#!/usr/bin/env python3
"""Run the LLM-powered placement agent."""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # Use second GPU

from agent.orchestrator import create_agent


def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            ğŸ“ PLACEMENT RAG AGENT (LLM-Powered)                  â•‘
â•‘                                                                  â•‘
â•‘   This agent uses LLM for:                                       â•‘
â•‘   â€¢ Query understanding & planning                               â•‘
â•‘   â€¢ Result validation & critique                                 â•‘
â•‘   â€¢ Natural response generation                                  â•‘
â•‘                                                                  â•‘
â•‘   Commands: 'quit' | 'verbose' | 'companies' | 'nollm'           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("ğŸ”„ Initializing LLM-powered agent (this may take a moment)...")
    
    use_llm = True
    agent = create_agent(use_llm=use_llm)
    
    companies = agent.get_companies()
    print(f"âœ… Ready! {len(companies)} companies loaded.")
    print(f"ğŸ“‹ Sample: {', '.join(companies[:5])}...\n")
    
    verbose = False
    
    while True:
        try:
            query = input("ğŸ“ Your question: ").strip()
            
            if not query:
                continue
            
            if query.lower() in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ Goodbye! Good luck with your placements! ğŸ‰")
                break
            
            if query.lower() == 'verbose':
                verbose = not verbose
                print(f"ğŸ“¢ Verbose mode: {'ON' if verbose else 'OFF'}\n")
                continue
            
            if query.lower() == 'companies':
                print(f"\nğŸ“‹ Available companies ({len(companies)}):")
                for i, c in enumerate(companies, 1):
                    print(f"   {i}. {c}")
                print()
                continue
            
            if query.lower() == 'nollm':
                use_llm = not use_llm
                agent = create_agent(use_llm=use_llm)
                print(f"ğŸ¤– LLM mode: {'ON' if use_llm else 'OFF (rule-based)'}\n")
                continue
            
            # Process query
            response = agent.query(query, verbose=verbose)
            
            print("\n" + "â”€" * 60)
            print(response.answer)
            print("â”€" * 60)
            
            conf = response.feedback.confidence_score
            conf_icon = "ğŸŸ¢" if conf > 0.7 else "ğŸŸ¡" if conf > 0.4 else "ğŸ”´"
            print(f"{conf_icon} Confidence: {conf:.0%}")
            
            if response.retries > 0:
                print(f"ğŸ”„ Retries: {response.retries}")
            print()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye! Good luck with your placements! ğŸ‰")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}\n")


if __name__ == "__main__":
    main()
